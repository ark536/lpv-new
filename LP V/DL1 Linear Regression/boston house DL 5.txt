1]!pip install tensorflow
!pip install tensorflow[and-cuda]

2]import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Flatten
from sklearn import preprocessing
import matplotlib.pyplot as plt

3]
(X_train, Y_train), (X_test, Y_test) = keras.datasets.boston_housing.load_data()

4]
print("Training data shape:", X_train.shape)
print("Test data shape:", X_test.shape)
print("Train output data shape:", Y_train.shape)
print("Actual Test output data shape:", Y_test.shape)

5]
X_train=preprocessing.normalize(X_train)
X_test=preprocessing.normalize(X_test)

6]
model = Sequential()
model.add(Dense(128,activation='relu',input_shape= X_train[0].shape))
model.add(Dense(64,activation='relu'))
model.add(Dense(32,activation='relu'))
model.add(Dense(1))

7]
model.summary()

8]model.compile(loss='mse',optimizer='rmsprop',metrics=['mae'])

9]history = model.fit(X_train,Y_train,epochs=100,batch_size=1,verbose=1,validation_data=(X_test,Y_test))

10]
def plot_loss(history):
    plt.figure(figsize=(20,5))
    plt.plot(history.history['loss'], 'g', label='Training Loss')
    plt.plot(history.history['val_loss'], 'b', label='Validation Loss')
    plt.xlim([0, 100])
    plt.ylim([0, 300])
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
11]
plot_loss(history)

12]
x = [3, 4, 5, 6, 7]
y_pred = model.predict(X_test)
for idx in range(len(x)):
    print("Predicted price of a home with {} rooms: ${}K".format(x[idx], int(y_pred[idx]*10)/10))

